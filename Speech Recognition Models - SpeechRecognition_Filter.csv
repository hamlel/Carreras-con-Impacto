Nombre ,Link,Task,Benchmark,Modelo,WER,CER,ExtraTraining Data,Parametros M ,Arquitectura,Fecha,FLOPS,Datos de entrenamiento en horas
A Comparative Study on Transformer vs RNN in Speech Applications,https://arxiv.org/pdf/1909.06317v2,Speech Recognition,AISHELL-1,CTC/Att,6.7,,FALSE,,,2019-09-13,,170
A Comparative Study on Transformer vs RNN in Speech Applications,https://arxiv.org/pdf/1909.06317v2,Speech Recognition,LibriSpeech test-clean,Transformer,2.6,,TRUE,,Transformer,2019-09-13,,960
A Comparative Study on Transformer vs RNN in Speech Applications,https://arxiv.org/pdf/1909.06317v2,Speech Recognition,LibriSpeech test-other,Transformer,5.7,,TRUE,,Transformer,2019-09-13,,960
Amortized Neural Networks for Low-Latency Speech Recognition,https://arxiv.org/pdf/2108.01553v1,Speech Recognition,LibriSpeech test-clean,AmNet,8.6,,FALSE,3.30E+07,,2021-08-03,2.53E+07,960
ASAPP-ASR: Multistream CNN and Self-Attentive SRU for SOTA Speech Recognition,https://arxiv.org/pdf/2005.10469v1,Speech Recognition,LibriSpeech test-other,Multistream CNN with Self-Attentive SRU,4.46,,FALSE,,,2020-05-21,1.67E+18,960
ASAPP-ASR: Multistream CNN and Self-Attentive SRU for SOTA Speech Recognition,https://arxiv.org/pdf/2005.10469v1,Speech Recognition,LibriSpeech test-clean,Multistream CNN with Self-Attentive SRU (WER includes text normalization),1.75,,FALSE,,CNN,2020-05-21,1.67E+18,
Audio-visual Recognition of Overlapped speech for the LRS2 dataset,https://arxiv.org/pdf/2001.01656v1,Automatic Speech Recognition (ASR),LRS2,LF-MMI TDNN,6.7,,,,,2020-01-06,,
Audio-Visual Speech Recognition With A Hybrid CTC/Attention Architecture,https://arxiv.org/pdf/1810.00108v1,Automatic Speech Recognition (ASR),LRS2,CTC/attention,8.2,,,,,2018-09-28,,
Auto-AVSR: Audio-Visual Speech Recognition with Automatic Labels,https://arxiv.org/pdf/2303.14307v3,Automatic Speech Recognition (ASR),LRS2,CTC/Attention,1.5,,,,,2023-03-25,,
Auto-AVSR: Audio-Visual Speech Recognition with Automatic Labels,https://arxiv.org/pdf/2303.14307v3,Automatic Speech Recognition (ASR), LRS3-TED,CTC/Attention,1,,FALSE,,,2023-03-25,,1921
Auto-AVSR: Audio-Visual Speech Recognition with Automatic Labels,https://arxiv.org/pdf/2303.14307v3,Visual Speech Recognition,LRS3-TED,CTC/Attention,19.1,,TRUE,,,2023-03-25,,3448
Automatic Speech Recognition in German: A Detailed Error Analysis,https://arxiv.org/ftp/arxiv/papers/2204/2204.05617.pdf,Automatic Speech Recognition (ASR),HUI speech corpus,Conformer Transducer,1.89,,TRUE,1.18E+08,,2022-08-03,1.36E+13,326
Automatic Speech Recognition in German: A Detailed Error Analysis,https://arxiv.org/ftp/arxiv/papers/2204/2204.05617.pdf,Automatic Speech Recognition (ASR),The Spoken Wikipedia Corpora,Conformer Transducer,8.04,,TRUE,1.18E+08,,2022-08-03,1.19E+13,285
Automatic Speech Recognition in German: A Detailed Error Analysis,https://arxiv.org/ftp/arxiv/papers/2204/2204.05617.pdf,Automatic Speech Recognition (ASR),Voxforge German,Conformer Transducer,3.36,,TRUE,1.18E+08,,2022-08-03,1.46E+12,35
Automatic Speech Recognition in German: A Detailed Error Analysis,https://arxiv.org/ftp/arxiv/papers/2204/2204.05617.pdf,Automatic Speech Recognition (ASR),M-AILabs speech dataset,Conformer Transducer,4.28,,TRUE,1.18E+08,,2022-08-03,9.85E+12,237
Automatic Speech Recognition in German: A Detailed Error Analysis,https://arxiv.org/ftp/arxiv/papers/2204/2204.05617.pdf,Automatic Speech Recognition (ASR),VoxPopuli,Conformer Transducer (German),8.98,,,1.18E+08,,2022-08-03,1.11E+13,268
Automatic Speech Recognition in German: A Detailed Error Analysis,https://arxiv.org/ftp/arxiv/papers/2204/2204.05617.pdf,Speech Recognition,Common Voice German,Conformer Transducer (no LM),6.28,,TRUE,1.18E+08,,2022-08-03,4.01E+13,965
BAT: Boundary aware transducer for memory-efficient and low-latency ASR,https://arxiv.org/pdf/2305.11571v1,Speech Recognition,AISHELL-1,BAT,4.97,,FALSE,9.00E+07,,2023-05-19,1.01E+18,
Beyond Universal Transformer: block reusing with adaptor in Transformer for automatic speech recognition,https://arxiv.org/pdf/2303.13072v2,Speech Recognition,AISHELL-1,BRA-E,6.63,,FALSE,8.50E+06,,2023-03-23,,
BigSSL: Exploring the Frontier of Large-Scale Semi-Supervised Learning for Automatic Speech Recognition,https://arxiv.org/pdf/2109.13226v3,Speech Recognition,WSJ eval92,ConformerXXL-P,1.3,,FALSE,1.00E+09,,2021-09-27,,
Building state-of-the-art distant speech recognition using the CHiME-4 challenge with a setup of speech enhancement baseline,https://arxiv.org/pdf/1803.10109v1,Distant Speech Recognition,CHiME-4 real 6ch,HMM-TDNN(LFMMI) + LSTMLM + NN-GEV,2.74,,FALSE,,,2018-03-27,,
CAT: A CTC-CRF based ASR Toolkit Bridging the Hybrid and the End-to-end Approaches towards Data Efficiency and Low Latency,https://arxiv.org/pdf/2005.13326v2,Speech Recognition,AISHELL-1,CTC-CRF 4gram-LM,6.34,,FALSE,3.70E+07,,2020-05-27,,170
CAT: A CTC-CRF based ASR Toolkit Bridging the Hybrid and the End-to-end Approaches towards Data Efficiency and Low Latency,https://arxiv.org/pdf/2005.13326v2,Speech Recognition,WSJ eval92,CTC-CRF VGG-BLSTM,3.2,,FALSE,1.60E+07,LSTM,2020-05-27,,80
Conformer: Convolution-augmented Transformer for Speech Recognition,https://arxiv.org/pdf/2005.08100v1,Speech Recognition,LibriSpeech test-clean,Conformer(L),1.9,,FALSE,1.19E+08,Conformer,2020-05-16,,970
Conformer: Convolution-augmented Transformer for Speech Recognition,https://arxiv.org/pdf/2005.08100v1,Speech Recognition,LibriSpeech test-other,Conformer(L),3.9,,TRUE,1.19E+08,Conformer,2020-05-16,,970
Conformer: Convolution-augmented Transformer for Speech Recognition,https://arxiv.org/pdf/2005.08100v1,Speech Recognition,LibriSpeech test-clean,Conformer(M),2,,TRUE,3.07E+07,Conformer,2020-05-16,,970
Conformer: Convolution-augmented Transformer for Speech Recognition,https://arxiv.org/pdf/2005.08100v1,Speech Recognition,LibriSpeech test-other,Conformer(M),4.3,,TRUE,3.07E+07,Conformer,2020-05-16,,970
Conformer: Convolution-augmented Transformer for Speech Recognition,https://arxiv.org/pdf/2005.08100v1,Speech Recognition,LibriSpeech test-clean,Conformer(S),2.1,,FALSE,1.03E+07,Conformer,2020-05-16,,970
Conformer: Convolution-augmented Transformer for Speech Recognition,https://arxiv.org/pdf/2005.08100v1,Speech Recognition,LibriSpeech test-other,Conformer(S),5,,TRUE,1.03E+07,Conformer,2020-05-16,,970
ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context,https://arxiv.org/pdf/2005.03191v3,Speech Recognition,LibriSpeech test-clean,ContextNet(L),1.9,,FALSE,1.13E+08,,2020-05-07,2.65E+09,970
ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context,https://arxiv.org/pdf/2005.03191v3,Speech Recognition,LibriSpeech test-other,ContextNet(L),4.1,,FALSE,1.13E+08,CNN-LSTM,2020-05-07,2.65E+09,970
ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context,https://arxiv.org/pdf/2005.03191v3,Speech Recognition,LibriSpeech test-clean,ContextNet(M),2,,TRUE,3.14E+07,,2020-05-07,2.65E+09,970
ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context,https://arxiv.org/pdf/2005.03191v3,Speech Recognition,LibriSpeech test-other,ContextNet(M),4.5,,TRUE,3.14E+07,CNN-LSTM,2020-05-07,2.65E+09,970
ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context,https://arxiv.org/pdf/2005.03191v3,Speech Recognition,LibriSpeech test-clean,ContextNet(S),2.3,,TRUE,1.08E+07,,2020-05-07,2.65E+09,970
ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context,https://arxiv.org/pdf/2005.03191v3,Speech Recognition,LibriSpeech test-other,ContextNet(S),5.5,,TRUE,1.08E+07,CNN-LSTM,2020-05-07,2.65E+09,970
CRF-based Single-stage Acoustic Modeling with CTC Topology,http://oa.ee.tsinghua.edu.cn/~ouzhijian/pdf/ctc-crf.pdf,Speech Recognition,LibriSpeech test-clean,CTC-CRF 4gram-LM,4.09,,FALSE,1.30E+07,,2019-04-16,1.04E+15,1000
CRF-based Single-stage Acoustic Modeling with CTC Topology,http://oa.ee.tsinghua.edu.cn/~ouzhijian/pdf/ctc-crf.pdf,Speech Recognition,LibriSpeech test-other,CTC-CRF 4gram-LM,10.65,,FALSE,1.30E+07,,2019-04-16,1.04E+15,1000
CRF-based Single-stage Acoustic Modeling with CTC Topology,http://oa.ee.tsinghua.edu.cn/~ouzhijian/pdf/ctc-crf.pdf,Speech Recognition,WSJ eval92,CTC-CRF 4gram-LM,3.79,,FALSE,1.30E+07,,2019-04-16,1.04E+15,80
"data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language",https://arxiv.org/pdf/2202.03555v3,Speech Recognition,LibriSpeech test-other,data2vec,3.7,,FALSE,,,2022-02-07,,
Deep Audio-Visual Speech Recognition,https://arxiv.org/pdf/1809.02108v2,Automatic Speech Recognition (ASR),LRS2,TM-CTC,10.1,,,,,2018-09-06,2.41E+14,195
Deep Audio-Visual Speech Recognition,https://arxiv.org/pdf/1809.02108v2,Automatic Speech Recognition (ASR),LRS2,TM-seq2seq,9.7,,,,,2018-09-06,3.85E+14,195
Deep Recurrent Neural Networks for Acoustic Modelling,https://arxiv.org/pdf/1504.01482v1,Speech Recognition,WSJ eval92,TC-DNN-BLSTM-DNN,3.5,,FALSE,,LSTM,2015-04-07,5.39E+16,81
Deep Speech 2: End-to-End Speech Recognition in English and Mandarin,https://arxiv.org/pdf/1512.02595v1,Speech Recognition,LibriSpeech test-clean,Deep Speech 2,5.33,,FALSE,1.00E+08,,2015-12-08,,960
Deep Speech 2: End-to-End Speech Recognition in English and Mandarin,https://arxiv.org/pdf/1512.02595v1,Speech Recognition,LibriSpeech test-other,Deep Speech 2,13.25,,FALSE,1.00E+08,,2015-12-08,,960
Deep Speech 2: End-to-End Speech Recognition in English and Mandarin,https://arxiv.org/pdf/1512.02595v1,Speech Recognition,WSJ eval92,Deep Speech 2,3.6,,TRUE,1.00E+08,,2015-12-08,,80
E-Branchformer: Branchformer with Enhanced merging for speech recognition,https://arxiv.org/pdf/2210.00077v2,Speech Recognition,LibriSpeech test-clean,E-Branchformer (L) + Internal Language Model Estimation,1.81,,FALSE,1.49E+08,E-Branchformer,2022-09-30,5.39E+16,960
E-Branchformer: Branchformer with Enhanced merging for speech recognition,https://arxiv.org/pdf/2210.00077v2,Speech Recognition,LibriSpeech test-other,E-Branchformer (L) + Internal Language Model Estimation,3.65,,FALSE,1.49E+08,,2022-09-30,5.39E+16,1000
Efficient Neural Architecture Search for End-to-end Speech Recognition via Straight-Through Gradients,https://arxiv.org/pdf/2011.05649v1,Speech Recognition,WSJ eval92,CTC-CRF ST-NAS,2.77,,FALSE,1.19E+07,,2020-11-11,1.70E+13,80
End-to-end ASR: from Supervised to Semi-Supervised Learning with Modern Architectures,https://arxiv.org/pdf/1911.08460v3,Speech Recognition,LibriSpeech test-other,Conv + Transformer AM (ConvLM with Transformer Rescoring),4.11,,TRUE,2.96E+08,Transformer-CNN,2019-11-19,,960
End-to-end ASR: from Supervised to Semi-Supervised Learning with Modern Architectures,https://arxiv.org/pdf/1911.08460v3,Speech Recognition,LibriSpeech test-other,Conv + Transformer AM (ConvLM with Transformer Rescoring) (LS only),5.18,,FALSE,2.70E+08,,2019-11-19,,
End-to-end ASR: from Supervised to Semi-Supervised Learning with Modern Architectures,https://arxiv.org/pdf/1911.08460v3,Speech Recognition,LibriSpeech test-clean,Conv + Transformer AM + Pseudo-Labeling (ConvLM with Transformer Rescoring),2.03,,FALSE,,Transformer,2019-11-19,,
End-to-end Audio-visual Speech Recognition with Conformers,https://arxiv.org/pdf/2102.06657v1,Automatic Speech Recognition (ASR),LRS2,End2end Conformer,3.9,,,3.85E+06,,2021-02-12,,381
End-to-end speech recognition using lattice-free MMI,https://www.danielpovey.com/files/2018_interspeech_end2end.pdf,Speech Recognition,WSJ eval92,End-to-end LF-MMI,3,,FALSE,8.20E+06,,2018-09-06,3.06E+13,80
End-to-end Speech Recognition with Adaptive Computation Steps,https://arxiv.org/pdf/1808.10088v2,Speech Recognition,AISHELL-1,Att,18.7,,FALSE,,,2018-08-30,,160
Espresso: A Fast End-to-end Neural Speech Recognition Toolkit,https://arxiv.org/pdf/1909.08723v3,Speech Recognition,WSJ eval92,Convolutional Speech Recognition,3.5,,FALSE,1.80E+07,,2018-12-17,4.12E+11,1380
Espresso: A Fast End-to-end Neural Speech Recognition Toolkit,https://arxiv.org/pdf/1909.08723v3,Speech Recognition,LibriSpeech test-clean,Espresso,2.8,,FALSE,2.50E+07,,2019-09-18,4.12E+11,1380
Espresso: A Fast End-to-end Neural Speech Recognition Toolkit,https://arxiv.org/pdf/1909.08723v3,Speech Recognition,LibriSpeech test-other,Espresso,8.7,,FALSE,1.74E+08,,2019-09-18,4.12E+11,1380
Espresso: A Fast End-to-end Neural Speech Recognition Toolkit,https://arxiv.org/pdf/1909.08723v3,Speech Recognition,WSJ eval92,Espresso,3.4,,FALSE,1.13E+08,,2019-09-18,4.12E+11,1380
FAdam: Adam is a natural gradient optimizer using diagonal empirical Fisher information,https://arxiv.org/pdf/2405.12807v8,Speech Recognition,LibriSpeech test-clean,FAdam,1.34,,FALSE,6.00E+08,,2024-05-21,,
FAdam: Adam is a natural gradient optimizer using diagonal empirical Fisher information,https://arxiv.org/pdf/2405.12807v8,Speech Recognition,LibriSpeech test-other,FAdam,2.49,,FALSE,6.00E+08,,2024-05-21,,
Fast Conformer with Linearly Scalable Attention for Efficient Speech Recognition,https://arxiv.org/pdf/2305.05084v6,Speech Recognition,LibriSpeech test-clean,parakeet-rnnt-1.1b,1.46,,FALSE,1.10E+09,,2023-05-08,6.08E+18,
Fast Conformer with Linearly Scalable Attention for Efficient Speech Recognition,https://arxiv.org/pdf/2305.05084v6,Speech Recognition,LibriSpeech test-other,parakeet-rnnt-1.1b,2.48,,FALSE,1.10E+09,,2023-05-08,6.08E+18,
"Faster, Simpler and More Accurate Hybrid ASR Systems Using Wordpieces",https://arxiv.org/pdf/2005.09150v2,Speech Recognition,LibriSpeech test-clean,CTC + Transformer LM rescoring,2.1,,FALSE,1.24E+08,Transformer,2020-05-19,1.95E+16,
"Faster, Simpler and More Accurate Hybrid ASR Systems Using Wordpieces",https://arxiv.org/pdf/2005.09150v2,Speech Recognition,LibriSpeech test-other,CTC + Transformer LM rescoring,4.2,,TRUE,1.24E+08,Transformer ,2020-05-19,1.95E+16,
Fully Convolutional Speech Recognition,https://arxiv.org/pdf/1812.06864v2,Speech Recognition,LibriSpeech test-clean,Convolutional Speech Recognition,3.26,,TRUE,,,2018-12-17,,
Fully Convolutional Speech Recognition,https://arxiv.org/pdf/1812.06864v2,Speech Recognition,LibriSpeech test-other,Convolutional Speech Recognition,10.47,,TRUE,,CNN,2018-12-17,,
FunASR: A Fundamental End-to-End Speech Recognition Toolkit,https://arxiv.org/pdf/2305.11013v1,Speech Recognition,AISHELL-1,Paraformer,4.95,,FALSE,4.63E+07,,2023-05-18,1.70E+15,
FunASR: A Fundamental End-to-End Speech Recognition Toolkit,https://arxiv.org/pdf/2305.11013v1,Speech Recognition,AISHELL-1,Paraformer-large,1.95,,TRUE,2.20E+08,,2023-05-18,1.70E+15,
Generative Speech Recognition Error Correction with Large Language Models and Task-Activating Prompting,https://arxiv.org/pdf/2309.15649v2,Speech Recognition,WSJ eval92,Task activating prompting generative correction,2.11,,TRUE,1.30E+10,,2023-09-27,,
HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units,https://arxiv.org/pdf/2106.07447v1,Speech Recognition,LibriSpeech test-clean,HuBERT with Libri-Light,1.8,,TRUE,3.17E+08,,2021-06-14,,
HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units,https://arxiv.org/pdf/2106.07447v1,Speech Recognition,LibriSpeech test-other,HuBERT with Libri-Light,2.9,,FALSE,9.64E+08,,2021-06-14,,
Improved Noisy Student Training for Automatic Speech Recognition,https://arxiv.org/pdf/2005.09629v2,Speech Recognition,LibriSpeech test-clean,ContextNet + SpecAugment-based Noisy Student Training with Libri-Light,1.7,,FALSE,,LSTM,2020-05-19,,
Improved Noisy Student Training for Automatic Speech Recognition,https://arxiv.org/pdf/2005.09629v2,Speech Recognition,LibriSpeech test-other,ContextNet + SpecAugment-based Noisy Student Training with Libri-Light,3.4,,FALSE,,CNN-LSTM,2020-05-19,,
Improved training of end-to-end attention models for speech recognition,https://arxiv.org/pdf/1805.03294v1,Speech Recognition,LibriSpeech test-clean,Seq-to-seq attention,3.82,,TRUE,,LSTM,2018-05-08,,
Improving End-to-End Speech Recognition with Policy Learning,https://arxiv.org/pdf/1712.07101v1,Speech Recognition,LibriSpeech test-clean,CTC + policy learning,5.42,,FALSE,,,2017-12-19,,
Improving Mandarin Speech Recogntion with Block-augmented Transformer,https://arxiv.org/pdf/2207.11697v5,Speech Recognition,AISHELL-1,SE-WSBO With LM,4.1,,FALSE,4.60E+07,,2022-07-24,5.24E+17,
Improving RNN Transducer Based ASR with Auxiliary Tasks,https://arxiv.org/pdf/2011.03109v2,Speech Recognition,LibriSpeech test-clean,Transformer Transducer,2,,FALSE,1.60E+08,Transformer,2020-11-05,,
Improving RNN Transducer Based ASR with Auxiliary Tasks,https://arxiv.org/pdf/2011.03109v2,Speech Recognition,LibriSpeech test-other,Transformer Transducer,4.2,,TRUE,1.60E+08,Transformer,2020-11-05,,
Iterative Pseudo-Labeling for Speech Recognition,https://arxiv.org/pdf/2005.09267v2,Speech Recognition,LibriSpeech test-clean,Conv + Transformer AM + Iterative Pseudo-Labeling (n-gram LM + Transformer Rescoring),2.1,,FALSE,3.22E+08,Transformer,2020-05-19,,
Iterative Pseudo-Labeling for Speech Recognition,https://arxiv.org/pdf/2005.09267v2,Speech Recognition,LibriSpeech test-other,Conv + Transformer AM + Iterative Pseudo-Labeling (n-gram LM + Transformer Rescoring),3.83,,FALSE,,,2020-05-19,,
Jasper: An End-to-End Convolutional Neural Acoustic Model,https://arxiv.org/pdf/1904.03288v3,Speech Recognition,WSJ eval92,Jasper 10x3,6.9,,FALSE,,,2019-04-05,1.02E+17,
Jasper: An End-to-End Convolutional Neural Acoustic Model,https://arxiv.org/pdf/1904.03288v3,Speech Recognition,LibriSpeech test-clean,Jasper DR 10x5,2.95,,FALSE,,,2019-04-05,1.02E+17,
Jasper: An End-to-End Convolutional Neural Acoustic Model,https://arxiv.org/pdf/1904.03288v3,Speech Recognition,LibriSpeech test-other,Jasper DR 10x5,8.79,,FALSE,,,2019-04-05,1.02E+17,
Jasper: An End-to-End Convolutional Neural Acoustic Model,https://arxiv.org/pdf/1904.03288v3,Speech Recognition,LibriSpeech test-clean,Jasper DR 10x5 (+ Time/Freq Masks),2.84,,FALSE,,,2019-04-05,1.02E+17,
Jasper: An End-to-End Convolutional Neural Acoustic Model,https://arxiv.org/pdf/1904.03288v3,Speech Recognition,LibriSpeech test-other,Jasper DR 10x5 (+ Time/Freq Masks),7.84,,FALSE,,,2019-04-05,1.02E+17,
Knowledge Transfer from Pre-trained Language Models to Cif-based Speech Recognizers via Hierarchical Distillation,https://arxiv.org/pdf/2301.13003v2,Speech Recognition,AISHELL-1,CIF-HKD With LM,4.1,,FALSE,4.70E+07,Knowledge Destilation,2023-01-30,,
Letter-Based Speech Recognition with Gated ConvNets,https://arxiv.org/pdf/1712.09444v2,Speech Recognition,LibriSpeech test-clean,Gated ConvNets,4.8,,FALSE,1.30E+08,,2017-12-22,,
Leveraging Unimodal Self-Supervised Learning for Multimodal Audio-Visual Speech Recognition,https://arxiv.org/pdf/2203.07996v2,Automatic Speech Recognition (ASR),LRS2,MoCo + wav2vec (w/o extLM),2.7,,,,,2022-02-24,2.10E+16,
Librispeech Transducer Model with Internal Language Model Prior Correction,https://arxiv.org/pdf/2104.03006v2,Speech Recognition,LibriSpeech test-clean,LSTM Transducer,2.23,,TRUE,,LSTM,2021-04-07,,
Librispeech Transducer Model with Internal Language Model Prior Correction,https://arxiv.org/pdf/2104.03006v2,Speech Recognition,LibriSpeech test-other,LSTM Transducer,5.6,,TRUE,,LSTM,2021-04-07,,
MMSpeech: Multi-modal Multi-task Encoder-Decoder Pre-training for Speech Recognition,https://arxiv.org/pdf/2212.00500v1,Speech Recognition,AISHELL-1,MMSpeech With LM,1.9,,FALSE,,Pretrained,2022-11-29,,
MT4SSL: Boosting Self-Supervised Speech Representation Learning by Integrating Multiple Targets,https://arxiv.org/pdf/2211.07321v3,Speech Recognition,LibriSpeech test-clean,MT4SSL,3.4,,FALSE,,,2022-11-14,1.73E+16,
MT4SSL: Boosting Self-Supervised Speech Representation Learning by Integrating Multiple Targets,https://arxiv.org/pdf/2211.07321v3,Speech Recognition,LibriSpeech test-other,MT4SSL,9.6,,FALSE,,,2022-11-14,1.73E+16,
Multi-Head State Space Model for Speech Recognition,https://arxiv.org/pdf/2305.12498v2,Speech Recognition,LibriSpeech test-clean,Stateformer,1.76,,FALSE,1.40E+08,,2023-05-21,,
NeMo: a toolkit for building AI applications using Neural Modules,https://arxiv.org/pdf/1909.09577v1,Speech Recognition,Common Voice German,ConformerCTC-L (4-gram),6.03,,TRUE,,,2021-11-24,,
NeMo: a toolkit for building AI applications using Neural Modules,https://arxiv.org/pdf/1909.09577v1,Speech Recognition,Common Voice Spanish,ConformerCTC-L (4-gram),5.5,,TRUE,,,2022-03-02,,
NeMo: a toolkit for building AI applications using Neural Modules,https://arxiv.org/pdf/1909.09577v1,Speech Recognition,Common Voice French,ConformerCTC-L (4-gram),9.16,,TRUE,,,2021-12-15,,
NeMo: a toolkit for building AI applications using Neural Modules,https://arxiv.org/pdf/1909.09577v1,Speech Recognition,Common Voice German,ConformerCTC-L (no LM),6.68,,TRUE,,,2021-11-24,,
NeMo: a toolkit for building AI applications using Neural Modules,https://arxiv.org/pdf/1909.09577v1,Speech Recognition,Common Voice Spanish,ConformerCTC-L (no LM),6.9,,TRUE,,,2022-03-02,,
NeMo: a toolkit for building AI applications using Neural Modules,https://arxiv.org/pdf/1909.09577v1,Speech Recognition,Common Voice French,ConformerCTC-L (no-LM),9.63,,TRUE,,,2021-12-15,,
Neural Network Language Modeling with Letter-based Features and Importance Sampling,https://www.cs.jhu.edu/~hxu/neural-network-language.pdf,Speech Recognition,LibriSpeech test-clean,tdnn + chain + rnnlm rescoring,3.06,,FALSE,,LSTM,2018-04-15,,
Neural Network Language Modeling with Letter-based Features and Importance Sampling,https://www.cs.jhu.edu/~hxu/neural-network-language.pdf,Speech Recognition,LibriSpeech test-other,tdnn + chain + rnnlm rescoring,7.63,,TRUE,,LSTM,2018-04-15,,
On the Choice of Modeling Unit for Sequence-to-Sequence Speech Recognition,https://arxiv.org/pdf/1902.01955v2,Speech Recognition,LibriSpeech test-clean,Model Unit Exploration,3.6,,FALSE,,,2019-02-05,,
Purely sequence-trained neural networks for ASR based on lattice-free MMI,https://www.danielpovey.com/files/2016_interspeech_mmi.pdf,Speech Recognition,WSJ eval92,tdnn + chain,2.32,,FALSE,,,2016-09-08,,
Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition,https://arxiv.org/pdf/2010.10504v2,Speech Recognition,LibriSpeech test-clean,Conformer + Wav2vec 2.0 + SpecAugment-based Noisy Student Training with Libri-Light,1.4,,TRUE,,,2020-10-20,,
Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition,https://arxiv.org/pdf/2010.10504v2,Speech Recognition,LibriSpeech test-other,Conformer + Wav2vec 2.0 + SpecAugment-based Noisy Student Training with Libri-Light,2.6,,FALSE,,Conformer ,2020-10-20,,
QuartzNet: Deep Automatic Speech Recognition with 1D Time-Channel Separable Convolutions,https://arxiv.org/pdf/1910.10261v1,Speech Recognition,LibriSpeech test-clean,QuartzNet15x5,2.69,,FALSE,,,2019-10-22,1.25E+15,
QuartzNet: Deep Automatic Speech Recognition with 1D Time-Channel Separable Convolutions,https://arxiv.org/pdf/1910.10261v1,Speech Recognition,LibriSpeech test-other,QuartzNet15x5,7.25,,FALSE,,,2019-10-22,1.25E+15,
Qwen-Audio: Advancing Universal Audio Understanding via Unified Large-Scale Audio-Language Models,https://arxiv.org/pdf/2311.07919v2,Speech Recognition,LibriSpeech test-clean,Qwen-Audio,2,,FALSE,,,2023-11-15,,
Qwen-Audio: Advancing Universal Audio Understanding via Unified Large-Scale Audio-Language Models,https://arxiv.org/pdf/2311.07919v2,Speech Recognition,LibriSpeech test-other,Qwen-Audio,4.2,,FALSE,,,2023-11-15,,
Qwen-Audio: Advancing Universal Audio Understanding via Unified Large-Scale Audio-Language Models,https://arxiv.org/pdf/2311.07919v2,Speech Recognition,AISHELL-1,Qwen-Audio,1.29,,TRUE,,,2023-11-15,,
Relaxed Attention: A Simple Method to Boost Performance of End-to-End Automatic Speech Recognition,https://arxiv.org/pdf/2107.01275v2,Speech Recognition,LibriSpeech test-other,Conformer with Relaxed Attention,6.85,,FALSE,,,2021-07-02,,
Relaxed Attention: A Simple Method to Boost Performance of End-to-End Automatic Speech Recognition,https://arxiv.org/pdf/2107.01275v2,Speech Recognition,WSJ eval92,Transformer with Relaxed Attention,3.19,,FALSE,,Transformer,2021-07-02,,
Robust Speech Recognition via Large-Scale Weak Supervision,https://arxiv.org/pdf/2212.04356v1,Speech Recognition,Common Voice German,Whisper (Large v2),6.4,,TRUE,,,2022-12-06,,
Robust Speech Recognition via Large-Scale Weak Supervision,https://arxiv.org/pdf/2212.04356v1,Speech Recognition,Common Voice Spanish,Whisper (Large v2),5.6,,TRUE,,,2022-12-06,,
Robust Speech Recognition via Large-Scale Weak Supervision,https://arxiv.org/pdf/2212.04356v1,Speech Recognition,Common Voice French,Whisper (Large v2),13.9,,TRUE,,,2022-12-06,,
RWTH ASR Systems for LibriSpeech: Hybrid vs Attention -- w/o Data Augmentation,https://arxiv.org/pdf/1905.03072v3,Speech Recognition,LibriSpeech test-clean,Hybrid model with Transformer rescoring,2.3,,FALSE,,Transformer,2019-05-08,,
RWTH ASR Systems for LibriSpeech: Hybrid vs Attention -- w/o Data Augmentation,https://arxiv.org/pdf/1905.03072v3,Speech Recognition,LibriSpeech test-other,Hybrid model with Transformer rescoring,5,,FALSE,,,2019-05-08,,
Scribosermo: Fast Speech-to-Text models for German and other Languages,https://arxiv.org/pdf/2110.07982v1,Speech Recognition,Common Voice German,ConformerCTC-L (5-gram),4.05,1.37%,TRUE,,,2022-08-12,,
Scribosermo: Fast Speech-to-Text models for German and other Languages,https://arxiv.org/pdf/2110.07982v1,Speech Recognition,Common Voice Spanish,ConformerCTC-L (5-gram),5.68,,TRUE,,,2022-09-13,,
Scribosermo: Fast Speech-to-Text models for German and other Languages,https://arxiv.org/pdf/2110.07982v1,Speech Recognition,Common Voice French,ConformerCTC-L (5-gram),8.13,,TRUE,,,2022-09-13,,
Scribosermo: Fast Speech-to-Text models for German and other Languages,https://arxiv.org/pdf/2110.07982v1,Speech Recognition,Common Voice German,ConformerCTC-L (no LM),7.33,2.05%,TRUE,,,2022-08-12,,
Scribosermo: Fast Speech-to-Text models for German and other Languages,https://arxiv.org/pdf/2110.07982v1,Speech Recognition,Common Voice Spanish,ConformerCTC-L (no-LM),7.46,,TRUE,,,2022-09-13,,
Scribosermo: Fast Speech-to-Text models for German and other Languages,https://arxiv.org/pdf/2110.07982v1,Speech Recognition,Common Voice French,ConformerCTC-L (no-LM),10.19,,TRUE,,,2022-09-13,,
Scribosermo: Fast Speech-to-Text models for German and other Languages,https://arxiv.org/pdf/2110.07982v1,Speech Recognition,Common Voice German,"QuartzNet15x5DE (CV-only, 5-gram)",7.7,3.20%,FALSE,,,2021-04-01,,
Scribosermo: Fast Speech-to-Text models for German and other Languages,https://arxiv.org/pdf/2110.07982v1,Speech Recognition,Common Voice German,"QuartzNet15x5DE (D37, 5-gram)",6.6,2.70%,TRUE,,,2021-07-02,,
Scribosermo: Fast Speech-to-Text models for German and other Languages,https://arxiv.org/pdf/2110.07982v1,Speech Recognition,Common Voice Spanish,QuartzNet15x5ES (CV-only),10.5,,FALSE,,,2021-04-01,,
Scribosermo: Fast Speech-to-Text models for German and other Languages,https://arxiv.org/pdf/2110.07982v1,Speech Recognition,Common Voice Spanish,QuartzNet15x5ES (D8),10,,TRUE,,,2021-04-01,,
Scribosermo: Fast Speech-to-Text models for German and other Languages,https://arxiv.org/pdf/2110.07982v1,Speech Recognition,Common Voice French,QuartzNet15x5FR (CV-only),12.1,,FALSE,,,2021-04-01,,
Scribosermo: Fast Speech-to-Text models for German and other Languages,https://arxiv.org/pdf/2110.07982v1,Speech Recognition,Common Voice French,QuartzNet15x5FR (D7),11,,TRUE,,,2021-07-02,,
Self-training and Pre-training are Complementary for Speech Recognition,https://arxiv.org/pdf/2010.11430v1,Speech Recognition,LibriSpeech test-clean,Conv + Transformer + wav2vec2.0 + pseudo labeling,1.5,,TRUE,,Transformer,2020-10-22,,
Self-training and Pre-training are Complementary for Speech Recognition,https://arxiv.org/pdf/2010.11430v1,Speech Recognition,LibriSpeech test-other,Conv + Transformer + wav2vec2.0 + pseudo labeling,3.1,,FALSE,,Transformer-CNN,2020-10-22,,
Self-training and Pre-training are Complementary for Speech Recognition,https://arxiv.org/pdf/2010.11430v1,Speech Recognition,LibriSpeech test-clean,wav2vec_wav2letter,2.7,,FALSE,,,2020-10-22,,
Semi-Supervised Speech Recognition via Local Prior Matching,https://arxiv.org/pdf/2002.10336v1,Speech Recognition,LibriSpeech test-other,"Local Prior Matching (Large Model, ConvLM LM)",15.28,,FALSE,,,2020-02-24,,
Semi-Supervised Speech Recognition via Local Prior Matching,https://arxiv.org/pdf/2002.10336v1,Speech Recognition,LibriSpeech test-clean,Local Prior Matching (Large Model),7.19,,FALSE,,,2020-02-24,,
Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces,https://arxiv.org/pdf/1805.10190v3,Speech Recognition,LibriSpeech test-clean,Snips,6.4,,FALSE,,,2018-05-25,,
Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces,https://arxiv.org/pdf/1805.10190v3,Speech Recognition,LibriSpeech test-other,Snips,16.5,,FALSE,,,2018-05-25,,
SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition,https://arxiv.org/pdf/1904.08779v3,Speech Recognition,LibriSpeech test-clean,LAS (no LM),2.7,,TRUE,,,2019-04-18,,
SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition,https://arxiv.org/pdf/1904.08779v3,Speech Recognition,LibriSpeech test-other,LAS (no LM),6.5,,TRUE,,,2019-04-18,,
SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition,https://arxiv.org/pdf/1904.08779v3,Speech Recognition,LibriSpeech test-clean,LAS + SpecAugment,2.5,,TRUE,,,2019-04-18,,
SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition,https://arxiv.org/pdf/1904.08779v3,Speech Recognition,LibriSpeech test-other,LAS + SpecAugment,5.8,,TRUE,,,2019-04-18,,
SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition,https://arxiv.org/pdf/1904.08779v3,Speech Recognition,LibriSpeech test-clean,Squeezeformer (L),2.47,,FALSE,,Conformer,2022-06-02,,
SpeechStew: Simply Mix All Available Speech Recognition Data to Train One Large Neural Network,https://arxiv.org/pdf/2104.02133v3,Speech Recognition,LibriSpeech test-clean,SpeechStew (100M),2,,FALSE,,Conformer,2021-04-05,,
SpeechStew: Simply Mix All Available Speech Recognition Data to Train One Large Neural Network,https://arxiv.org/pdf/2104.02133v3,Speech Recognition,LibriSpeech test-other,SpeechStew (100M),4,,FALSE,,Conformer,2021-04-05,,
SpeechStew: Simply Mix All Available Speech Recognition Data to Train One Large Neural Network,https://arxiv.org/pdf/2104.02133v3,Speech Recognition,LibriSpeech test-clean,SpeechStew (1B),1.7,,FALSE,,Conformer,2021-04-05,,
SpeechStew: Simply Mix All Available Speech Recognition Data to Train One Large Neural Network,https://arxiv.org/pdf/2104.02133v3,Speech Recognition,LibriSpeech test-other,SpeechStew (1B),3.3,,FALSE,,Conformer,2021-04-05,,
SpeechStew: Simply Mix All Available Speech Recognition Data to Train One Large Neural Network,https://arxiv.org/pdf/2104.02133v3,Speech Recognition,WSJ eval92,Speechstew 100M,1.3,,TRUE,,,2021-04-05,,
Squeezeformer: An Efficient Transformer for Automatic Speech Recognition,https://arxiv.org/pdf/2206.00888v2,Speech Recognition,LibriSpeech test-clean,Conv + Transformer AM (ConvLM with Transformer Rescoring) (LS only),2.31,,FALSE,,Transformer,2019-11-19,,
Squeezeformer: An Efficient Transformer for Automatic Speech Recognition,https://arxiv.org/pdf/2206.00888v2,Speech Recognition,LibriSpeech test-other,Squeezeformer (L),5.97,,FALSE,,Conformer,2022-06-02,277.9GF,
State-of-the-Art Speech Recognition Using Multi-Stream Self-Attention With Dilated 1D Convolutions,https://arxiv.org/pdf/1910.00716v1,Speech Recognition,LibriSpeech test-clean,Multi-Stream Self-Attention With Dilated 1D Convolutions,2.2,,FALSE,,,2019-10-01,,
State-of-the-Art Speech Recognition Using Multi-Stream Self-Attention With Dilated 1D Convolutions,https://arxiv.org/pdf/1910.00716v1,Speech Recognition,LibriSpeech test-other,Multi-Stream Self-Attention With Dilated 1D Convolutions,5.8,,FALSE,,CNN,2019-10-01,,
TEVR: Improving Speech Recognition by Token Entropy Variance Reduction,https://arxiv.org/pdf/2206.12693v1,Speech Recognition,Common Voice German,wav2vec 2.0 XLS-R (no LM),12.06,,FALSE,,,2022-06-02,,
TEVR: Improving Speech Recognition by Token Entropy Variance Reduction,https://arxiv.org/pdf/2206.12693v1,Speech Recognition,Common Voice German,wav2vec 2.0 XLS-R 1B (5-gram),4.38,1.62%,TRUE,,,2022-06-02,,
TEVR: Improving Speech Recognition by Token Entropy Variance Reduction,https://arxiv.org/pdf/2206.12693v1,Speech Recognition,Common Voice German,wav2vec 2.0 XLS-R 1B + TEVR (4-gram),3.7,,TRUE,,,2022-06-02,,
TEVR: Improving Speech Recognition by Token Entropy Variance Reduction,https://arxiv.org/pdf/2206.12693v1,Speech Recognition,Common Voice German,wav2vec 2.0 XLS-R 1B + TEVR (5-gram),3.64,1.54%,TRUE,,,2022-06-02,,
TEVR: Improving Speech Recognition by Token Entropy Variance Reduction,https://arxiv.org/pdf/2206.12693v1,Speech Recognition,Common Voice German,wav2vec 2.0 XLS-R 1B + TEVR (no LM),10.1,,TRUE,,,2022-06-02,,
The PyTorch-Kaldi Speech Recognition Toolkit,https://arxiv.org/pdf/1811.07453v2,Speech Recognition,LibriSpeech test-clean,Li-GRU,6.2,,FALSE,,,2018-11-19,,
Transformer-based Acoustic Modeling for Hybrid Speech Recognition,https://arxiv.org/pdf/1910.09799v2,Speech Recognition,LibriSpeech test-clean,Hybrid + Transformer LM rescoring,2.26,,FALSE,,Transformer,2019-10-22,1.72E+17,
Transformer-based Acoustic Modeling for Hybrid Speech Recognition,https://arxiv.org/pdf/1910.09799v2,Speech Recognition,LibriSpeech test-other,hybrid + Transformer LM rescoring,4.85,,TRUE,,,2019-10-22,1.72E+17,
Transformer-based ASR Incorporating Time-reduction Layer and Fine-tuning with Self-Knowledge Distillation,https://arxiv.org/pdf/2103.09903v1,Speech Recognition,LibriSpeech test-clean,Transformer+Time reduction+Self Knowledge distillation,1.9,,FALSE,,Transformer,2021-03-17,,
Unified Streaming and Non-streaming Two-pass End-to-end Model for Speech Recognition,https://arxiv.org/pdf/2012.05481v2,Speech Recognition,AISHELL-1,CTC/Att,4.72,,FALSE,,,2020-12-10,,
Unified Streaming and Non-streaming Two-pass End-to-end Model for Speech Recognition,https://arxiv.org/pdf/2012.05481v2,Speech Recognition,AISHELL-1,U2,4.72,,FALSE,4.70E+07,,2020-12-10,,
Unimodal Aggregation for CTC-based Speech Recognition,https://arxiv.org/pdf/2309.08150v2,Speech Recognition,AISHELL-1,UMA,4.7,,FALSE,4.47E+07,,2023-09-15,,
"VoxPopuli: A Large-Scale Multilingual Speech Corpus for Representation Learning, Semi-Supervised Learning and Interpretation",https://arxiv.org/pdf/2101.00390v2,Speech Recognition,Common Voice German,VoxPopuli (n-gram),7.8,,TRUE,,,2021-01-02,3.41E+17,
"VoxPopuli: A Large-Scale Multilingual Speech Corpus for Representation Learning, Semi-Supervised Learning and Interpretation",https://arxiv.org/pdf/2101.00390v2,Speech Recognition,Common Voice Spanish,VoxPopuli-50K (n-gram),10,,TRUE,,,2021-01-02,2.20E+17,
"VoxPopuli: A Large-Scale Multilingual Speech Corpus for Representation Learning, Semi-Supervised Learning and Interpretation",https://arxiv.org/pdf/2101.00390v2,Speech Recognition,Common Voice French,VoxPopuli-50K (n-gram),9.6,,TRUE,,,2021-01-02,3.95E+17,
W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training,https://arxiv.org/pdf/2108.06209v2,Speech Recognition,LibriSpeech test-clean,w2v-BERT XXL,1.4,,TRUE,,,2021-08-07,,
W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training,https://arxiv.org/pdf/2108.06209v2,Speech Recognition,LibriSpeech test-other,w2v-BERT XXL,2.5,,FALSE,,,2021-08-07,,
wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations,https://arxiv.org/pdf/2006.11477v3,Speech Recognition,LibriSpeech test-other,wav2vec 2.0,4.1,,TRUE,,Transformer-CNN,2020-06-20,8.14E+15,
wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations,https://arxiv.org/pdf/2006.11477v3,Speech Recognition,LibriSpeech test-clean,wav2vec 2.0 with Libri-Light,1.8,,TRUE,,Transformer,2020-06-20,1.35E+17,
wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations,https://arxiv.org/pdf/2006.11477v3,Speech Recognition,LibriSpeech test-other,wav2vec 2.0 with Libri-Light,3.3,,FALSE,,Transformer-CNN,2020-06-20,1.35E+17,
WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing,https://arxiv.org/pdf/2110.13900v5,Speech Recognition,LibriSpeech test-clean,WavLM Large,1.8,,FALSE,,,2021-10-26,1.19E+17,
WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing,https://arxiv.org/pdf/2110.13900v5,Speech Recognition,LibriSpeech test-other,WavLM Large,3.2,,FALSE,,,2021-10-26,1.19E+17,
,,Speech Recognition,WSJ eval92,CNN over RAW speech (wav),5.6,,FALSE,,,,,
,,Distant Speech Recognition,CHiME-4 real 6ch,Complex Spectral Mapping + WRBN + Utterance-Wise Dropout + Iterative Speaker Adaptation,1.99,,FALSE,,,2020-01-09,,
,,Speech Recognition,LibriSpeech test-clean,HMM-(SAT)GMM,8,,TRUE,,HMM,,,
,,Speech Recognition,LibriSpeech test-clean,HMM-DNN + pNorm*,5.5,,TRUE,,HMM,,,
,,Speech Recognition,LibriSpeech test-clean,HMM-TDNN + iVectors,4.8,,TRUE,,HMM,,,
,,Speech Recognition,LibriSpeech test-clean,HMM-TDNN trained with MMI + data augmentation (speed) + iVectors + 3 regularizations,4.3,,FALSE,,HMM,,,
,,Speech Recognition,LibriSpeech test-other,TDNN + pNorm + speed up/down speech,12.5,,FALSE,,,2017-07-09,,
,,Speech Recognition,WSJ eval92,"test-set on open vocabulary (i.e. harder), model = HMM-DNN + pNorm*",3.6,,FALSE,,,,,